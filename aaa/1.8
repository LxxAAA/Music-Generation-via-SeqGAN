1.大致清楚了脉络，我自己的想法如果想继续，关键是D还有rollout那里，那是我首先想增加的点
2.之后再跟着主py再走一遍
3.还有的问题就是，用p100跑的话，有点慢！这个问题怎么解决！ 硬件的问题。
4.默默祝福自己顺利写出论文来
--------------------------------------------------------------------------------
19.1.8
1.主py走完一遍， 两个问题：1.rollout是怎么运作的 2.rewards对于G的影响是什么
      答： 目前粗略的看了下，
           问题1：rollout是G的阉割版本，有G的许多参数，但是只求gen_x。有两个主要的函数，一个是get reward，一个是update。 
          get reward主要是利用了自己的LSTM网络（G），以及D的网络，然后完成蒙塔卡罗搜索，来求得reward。
           问题2：reward只是在G的正式监督学习中， 充当了loss的一个正则项。
2.跑起来的确是慢，别急吧。

4.所以现在方向就是： 1.弄清楚seqGAN中的G的结构，D的结构，rollout的方式，思考能够如何改进
                    2.预处理这块如何改进，可以参考另外一个代码，迁移学习的那个代码
                    3.D如何做改进。
                    4.post处理是什么。是midi的相关嘛
       
3.明日任务：（1。上午看论文）把seqGAN网络好好看，带着问题去看 
              （一）G网络具体是怎样的，（lstm，以及rollout如何作用）
              （二）D网络具体是怎样的，我的想法如何放在D中
              （三）rollout具体是怎样的，我的想法如何放入rollout中，（MC是怎么用的）
           （2）（下午看强化学习）强化学习，MC搜索树研究一下，调研，并且思考我的想法怎么办
           （3）（晚上细细的钻预处理，有空再看D的评判构思是附加题）两个部分，一个是预处理的具体实现，我能怎么改进。第二个是D中，我的想法该怎样做。
